# 高并发

**高并发相关指标**

* 响应时间：系统对请求做出响应的时间。

* 吐出量：单位时间内处理的请求数量。

* 每秒查询率：每秒响应请求数。

* 并发用户数：同时承载正常使用系统功能的用户数量。

**同时承载正常使用系统功能的用户数量**

**垂直扩展：**

	1.  增强单机硬件性能，例如：增加CPU核数如32核，升级更好的网卡如万兆，升级更好的硬盘如SSD，扩充硬盘容量如2T，扩充系统内存如128G；
 	2.  提升单机架构性能，例如：使用Cache来减少IO次数，使用异步来增加单服务吞吐量，使用无锁数据结构来减少响应时间；

在互联网业务发展非常迅猛的早期，如果预算不是问题，强烈建议使用“增强单机硬件性能”的方式提升系统并发能力，因为这个阶段，公司的战略往往是发展业务抢时间，而“增强单机硬件性能”往往是最快的方法。

不管是提升单机硬件性能，还是提升单机架构性能，都有一个致命的不足：单机性能总是有极限的。所以互联网分布式架构设计高并发终极解决方案还是水平扩展。

**水平扩展：**

只要增加服务器数量，就能线性扩充系统性能。水平扩展对系统架构设计是有要求的，如何在架构各层进行可水平扩展的设计，以及互联网公司架构各层常见的水平扩展实践，是本文重点讨论的内容。

## 常见的互联网分层框架

![](C:\Users\wangjunzuo\Desktop\notebook\并发基础\pic\互联网分层框架.png)

	1. **客户端层**：典型调用方是浏览器browser或者手机应用APP
 	2. **反向代理层**：系统入口，反向代理
 	3. **站点应用层**：实现核心应用逻辑，返回html或者json
 	4. **服务层**：如果实现了服务化，就有这一层
 	5. **数据缓存层**：缓存加速访问存储
 	6. **数据数据库层**：数据库固化数据存储

## **分层水平扩展架构实践**

### 反向代理层的水平扩展

![](C:\Users\wangjunzuo\Desktop\notebook\并发基础\pic\反向代理层的逐步扩展.png)

反向代理层的水平扩展，是通过“DNS轮询”实现的：dns-server对于一个域名配置了多个解析ip，每次DNS解析请求来访问dns-server，会轮询返回这些ip。

当nginx成为瓶颈的时候，只要增加服务器数量，新增nginx服务的部署，增加一个外网ip，就能扩展反向代理层的性能，做到理论上的无限高并发。

### 站点层的水平扩展

![](C:\Users\wangjunzuo\Desktop\notebook\并发基础\pic\站层点的水平扩展.png)

站点层的水平扩展，是通过“nginx”实现的。通过修改nginx.conf，可以设置多个web后端。

当web后端成为瓶颈的时候，只要增加服务器数量，新增web服务的部署，在nginx配置中配置上新的web后端，就能扩展站点层的性能，做到理论上的无限高并发。

### 服务层的水平扩展

![](C:\Users\wangjunzuo\Desktop\notebook\并发基础\pic\服务层的水平扩展.png)

服务层的水平扩展，是通过“服务连接池”实现的。

站点层通过RPC-client调用下游的服务层RPC-server时，RPC-client中的连接池会建立与下游服务多个连接，当服务成为瓶颈的时候，只要增加服务器数量，新增服务部署，在RPC-client处建立新的下游服务连接，就能扩展服务层性能，做到理论上的无限高并发。如果需要优雅的进行服务层自动扩容，这里可能需要配置中心里服务自动发现功能的支持。

### 数据层的水平扩展

在数据量很大的情况下，数据层（缓存，数据库）涉及数据的水平扩展，将原本存储在一台服务器上的数据（缓存，数据库）水平拆分到不同服务器上去，以达到扩充系统性能的目的。

互联网数据层常见的水平拆分方式有这么几种，以数据库为例：

#### **按照范围水平拆分**

![](C:\Users\wangjunzuo\Desktop\notebook\并发基础\pic\范围水平拆分.webp)

每一个数据服务，存储一定范围的数据，上图为例：

user0库，存储uid范围1-1kw

user1库，存储uid范围1kw-2kw

这个方案的好处是：

	1. 规则简单，service只需判断一下uid范围就能路由到对应的存储服务；
 	2. 数据均衡性较好；
 	3. 比较容易扩展，可以随时加一个uid[2kw,3kw]的数据服务；

不足是：

​	1. 请求的负载不一定均衡，一般来说，新注册的用户会比老用户更活跃，大range的服务请求压力会更大；

#### **按照哈希水平拆分**

![](C:\Users\wangjunzuo\Desktop\notebook\并发基础\pic\哈希水平拆分.webp)

每一个数据库，存储某个key值hash后的部分数据，上图为例：

user0库，存储偶数uid数据

user1库，存储奇数uid数据

这个方案的好处是：

	1. 规则简单，service只需对uid进行hash能路由到对应的存储服务
 	2. 数据均衡性较好；

 	1. 请求均匀性较好；

不足是：

	1. 不容易扩展，扩展一个数据服务，hash方法改变时候，可能需要进行数据迁移；

这里需要注意的是，通过水平拆分来扩充系统性能，与主从同步读写分离来扩充数据库性能的方式有本质的不同。

通过水平拆分扩展数据库性能：

（1）每个服务器上存储的数据量是总量的1/n，所以单机的性能也会有提升；

（2）n个服务器上的数据没有交集，那个服务器上数据的并集是数据的全集；

（3）数据水平拆分到了n个服务器上，理论上读性能扩充了n倍，写性能也扩充了n倍（其实远不止n倍，因为单机的数据量变为了原来的1/n）；

通过主从同步读写分离扩展数据库性能：

（1）每个服务器上存储的数据量是和总量相同；

（2）n个服务器上的数据都一样，都是全集；

（3）理论上读性能扩充了n倍，写仍然是单点，写性能不变；

## 总结

**高并发（**High Concurrency）是互联网分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计保证系统能够同时并行处理很多请求。

提高系统并发能力的方式，方法论上主要有两种：垂直扩展（Scale Up）与水平扩展（Scale Out）。前者垂直扩展可以通过提升单机硬件性能，或者提升单机架构性能，来提高并发性，但单机性能总是有极限的，互联网分布式架构设计高并发终极解决方案还是后者：水平扩展。

互联网分层架构中，各层次水平扩展的实践又有所不同：

（1）反向代理层可以通过“DNS轮询”的方式来进行水平扩展；

（2）站点层可以通过nginx来进行水平扩展；

（3）服务层可以通过服务连接池来进行水平扩展；

（4）数据库可以按照数据范围，或者数据哈希的方式来进行水平扩展；

各层实施水平扩展后，能够通过增加服务器数量的方式来提升系统的性能，做到理论上的性能无限。

# 缓存

分布式缓存独立于应用部署的一个缓存集群，可以是Memcached缓存，也可以Redis缓存，应用读取缓存数据或者写入缓存数据都需要通过网络来进行，也就是说在分布式缓存中网络的开销不容忽视，有时候读一个缓存的绝大多数时间都花在网络开销上。其次就是本地缓存，本地缓存就是服务器本身通过自己的堆内/堆外存储的缓存，因为缓存数据位于服务器本身，所以有一定的大小限制（如果是JVM的堆内缓存的话要考虑Heap的大小等等，如果是堆外缓存的话也要考虑服务器本身缓存的大小）

**缓存特征：**

* 命中率
* 最大空间
* 清空策略：
  1. FIFO：最先进入缓存的数据，在缓存空间不足够的情况下，会被首先清理出去
  2. LFU [Less Frequently Used]：最少使用的缓存会被清理，这要求缓存的元素有 hit 属性，在缓存空间不够的情况下，hit值最小的将会被清理出去
  3. LRU [Least Recently Used]：最近最少使用的元素被清理，缓存的元素有一个时间戳，当缓存容量满了，而又要腾出地方缓存新元素时，现有缓存元素中时间戳离当前时间最远的元素将被清理出去

**缓存命中率影响因素**

* 业务场景和业务需求：

  缓存适合“读多写少”的业务场景，反之，使用缓存的意义其实并不大，命中率会很低。

  业务需求决定了对时效性的要求，直接影响到缓存的过期时间和更新策略。时效性要求越低，就越适合缓存。在相同key和相同请求数的情况下，缓存时间越长，命中率会越高。

* 缓存的设计(粒度和策略)：

  通常情况下，缓存的粒度越小，命中率会越高。举个实际的例子说明：

  当缓存单个对象的时候（例如：单个用户信息），只有当该对象对应的数据发生变化时，我们才需要更新缓存或者让移除缓存。而当缓存一个集合的时候（例如：所有用户数据），其中任何一个对象对应的数据发生变化时，都需要更新或移除缓存。

  还有另一种情况，假设其他地方也需要获取该对象对应的数据时（比如其他地方也需要获取单个用户信息），如果缓存的是单个对象，则可以直接命中缓存，反之，则无法直接命中。这样更加灵活，缓存命中率会更高。

  此外，缓存的更新/过期策略也直接影响到缓存的命中率。当数据发生变化时，直接更新缓存的值会比移除缓存（或者让缓存过期）的命中率更高，当然，系统复杂度也会更高。

* 缓存容量和基础设施

  缓存的容量有限，则容易引起缓存失效和被淘汰（目前多数的缓存框架或中间件都采用了LRU算法）。同时，缓存的技术选型也是至关重要的，比如采用应用内置的本地缓存就比较容易出现单机瓶颈，而采用分布式缓存则毕竟容易扩展。所以需要做好系统容量规划，并考虑是否可扩展。此外，不同的缓存框架或中间件，其效率和稳定性也是存在差异的。

* 其他因素

  当缓存节点发生故障时，需要避免缓存失效并最大程度降低影响，这种特殊情况也是架构师需要考虑的。业内比较典型的做法就是通过一致性Hash算法，或者通过节点冗余的方式。

缓存分类和应用场景

1. 本地缓存：Guava Cache
 	2. 分布式缓存:Memcache、Redis

高并发场景下缓存常见问题

1. 缓存一致性问题

 	2. 缓存并发问题
 	3. 缓存穿透问题
 	4. 缓存雪崩现象

# 消息队列

特性：

	1. 与业务无关：只做消息分发
 	2. FIFO：
 	3. 容灾：
 	4. 性能：

为什么需要消息队列：

	1. 生产和消费的速度或稳定性等因素不一致

好处：

	1. 业务解耦
 	2. 最终一致性
 	3. 广播
 	4. 错峰与流控

Kafka构架：

# 应用拆分

原则：

1. 业务优先

 	2. 边拆分边测试
 	3. 兼顾技术：重构、分层
 	4. 可靠测试

思考：

	1. 应用之间通信：PRC、消息队列
 	2. 应用之间数据库设计：每个应用都有独立的数据库
 	3. 避免事物操作跨应用

Dubbo框架：

# 应用限流

算法：

1. 计数器法

 	2. 滑动窗口
 	3. 漏桶算法
 	4. 令牌桶算法

 # 服务降级与服务熔断

服务降级分类：

1. 自动降级

 	2. 人工降级

共性：目的、最终表现、粒度、自制

区别：触发原因、管理目标层次、实现方式

# 数据库切库、分库、分表

## 切库

	1. 读写分离
 	2. 

# 高可用手段

 	1. 任务调度系统分布式：elastic-job+zookeeper
      	2. 主备切换：apache curator + zookeeper分布式锁实现
         	3. 监控报警机制





 